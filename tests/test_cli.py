"""
Unit tests for CLI module.
"""

from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

from click.testing import CliRunner
import pytest
import yaml

# Main CLI entrypoint
from ahc_agent.cli import cli
from ahc_agent.config import Config


class TestCLI:
    """
    Tests for CLI module.
    """

    @pytest.fixture()
    def runner(self):
        """
        Create a CLI runner for testing.
        """
        return CliRunner()

    def test_cli_help(self, runner):
        """
        Test CLI help command.
        """
        result = runner.invoke(cli, ["--help"])
        assert result.exit_code == 0
        assert "AHCAgent" in result.output
        assert "init" in result.output
        assert "solve" in result.output

    @patch("ahc_agent.cli.InitService")
    def test_init_command(self, MockInitService, runner):
        """Test basic init command flow."""
        mock_init_service_instance = MockInitService.return_value
        mock_init_service_instance.initialize_project = MagicMock(
            return_value={
                "project_dir": "/mocked/workspace/ahc001",
                "config_file_path": "/mocked/workspace/ahc001/config.yaml",
                "contest_id": "ahc001",
            }
        )

        result = runner.invoke(cli, ["init", "ahc001", "--workspace", "./workspace"])

        assert result.exit_code == 0
        MockInitService.assert_called_once_with()

        mock_init_service_instance.initialize_project.assert_called_once_with(
            contest_id="ahc001", workspace="./workspace", html_file=None, url="https://atcoder.jp/contests/ahc001/tasks/ahc001_a"
        )
        assert "Project for contest 'ahc001' initialized successfully" in result.output
        assert "/mocked/workspace/ahc001" in result.output

    @patch("ahc_agent.cli.InitService")
    def test_init_default_workspace(self, MockInitService, runner: CliRunner, tmp_path: Path):
        """Test init command with default workspace (uses contest_id as dir name)."""
        contest_id = "ahc999"

        mock_init_service_instance = MockInitService.return_value
        # Simulate the service creating paths relative to the execution directory (tmp_path here)
        # When runner.isolated_filesystem is used, CWD becomes that isolated dir.
        # InitService's default workspace logic (os.getcwd() / contest_id) will use this.
        # So, expected_project_dir should be relative to the isolated CWD.
        # For simplicity, we'll assume the service returns an absolute-like path for the mock.
        expected_project_dir = Path(tmp_path) / contest_id
        expected_config_path = expected_project_dir / "config.yaml"

        mock_init_service_instance.initialize_project = MagicMock(
            return_value={
                "project_dir": str(expected_project_dir),
                "config_file_path": str(expected_config_path),
                "contest_id": contest_id,
            }
        )

        with runner.isolated_filesystem(temp_dir=tmp_path) as _:
            result = runner.invoke(cli, ["init", contest_id])

            assert result.exit_code == 0
            mock_init_service_instance.initialize_project.assert_called_once_with(
                contest_id=contest_id, workspace=None, html_file=None, url=f"https://atcoder.jp/contests/{contest_id}/tasks/{contest_id}_a"
            )
            assert f"Project for contest '{contest_id}' initialized successfully" in result.output
            # The output path in the message comes from the mocked return value
            assert str(expected_project_dir) in result.output

    @patch("ahc_agent.cli.InitService")
    def test_init_with_workspace(self, MockInitService, runner: CliRunner, tmp_path: Path):
        """Test init command with a specified workspace."""
        contest_id = "ahc998"
        workspace_name = "my_custom_workspace"

        mock_init_service_instance = MockInitService.return_value
        expected_project_dir = tmp_path / workspace_name  # Service returns absolute-like path
        expected_config_path = expected_project_dir / "config.yaml"

        mock_init_service_instance.initialize_project = MagicMock(
            return_value={
                "project_dir": str(expected_project_dir),
                "config_file_path": str(expected_config_path),
                "contest_id": contest_id,
            }
        )

        with runner.isolated_filesystem(temp_dir=tmp_path) as _:
            result = runner.invoke(cli, ["init", contest_id, "--workspace", workspace_name])

            assert result.exit_code == 0
            mock_init_service_instance.initialize_project.assert_called_once_with(
                contest_id=contest_id, workspace=workspace_name, html_file=None, url=f"https://atcoder.jp/contests/{contest_id}/tasks/{contest_id}_a"
            )
            assert f"Project for contest '{contest_id}' initialized successfully" in result.output
            assert str(expected_project_dir) in result.output

    # Docker関連の機能を削除したため、このテストは不要になりました

    @patch("ahc_agent.cli.InitService")
    def test_init_command_with_existing_target_dir_as_file(self, MockInitService, runner, tmp_path):
        contest_id = "ahc888"

        # This test assumes that the CLI's InitService will handle the file existence check.
        # The CLI command catches RuntimeError from the service.
        mock_init_service_instance = MockInitService.return_value
        # Simulate the service raising an error because the target path is a file
        target_path_as_file_simulated_by_service = tmp_path / contest_id  # Path service would try to create
        mock_init_service_instance.initialize_project.side_effect = RuntimeError(
            f"Error creating project directory: '{target_path_as_file_simulated_by_service}' already exists and is a file or non-empty directory."
        )

        with runner.isolated_filesystem(temp_dir=tmp_path) as td:
            # Create the conflicting file within the isolated directory
            actual_conflicting_file = Path(td) / contest_id
            actual_conflicting_file.write_text("This is a file, not a directory.")

            result = runner.invoke(cli, ["init", contest_id])  # Workspace is implicitly contest_id in td

            assert result.exit_code == 1
            assert "Error during project initialization" in result.output
            # The error message from the service (containing the path) should be in the output
            assert str(target_path_as_file_simulated_by_service) in result.output

    @patch("ahc_agent.cli.DockerManager")
    @patch("ahc_agent.cli.LLMClient")
    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.WorkspaceStore")
    @patch("ahc_agent.cli.SolveService")
    def test_solve_group_default_non_interactive(self, MockSolveService, MockWorkspaceStore, MockCliConfig, MockLLMClient, MockDockerManager, runner):
        """Tests the default 'solve' command (no subcommand, not interactive)."""
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.side_effect = lambda key, default=None: {
            "contest_id": "test_contest",
            "workspace.base_dir": "/mocked/workspace/path", # Should be updated by cli
            "llm": {}, "docker": {},
        }.get(key, default)
        mock_workspace_config_instance.config_file_path = "/mocked/ws/config.yaml"
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_llm_instance = MockLLMClient.return_value
        mock_docker_instance = MockDockerManager.return_value
        mock_ws_store_instance = MockWorkspaceStore.return_value

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_solve = AsyncMock(return_value=None) # For non-interactive default

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            problem_file = workspace_path / "problem.md"
            problem_file.write_text("# Test Problem")
            config_file = workspace_path / "config.yaml"
            config_file.write_text(yaml.dump({"contest_id": "test_contest"}))

            result = runner.invoke(cli, ["solve", str(workspace_path)])

            assert result.exit_code == 0, result.output
            MockCliConfig.assert_called_once_with(str(config_file))
            # Check that base_dir in config was updated to the actual temp workspace_path
            mock_workspace_config_instance.set.assert_any_call("workspace.base_dir", str(workspace_path))

            MockLLMClient.assert_called_once_with({})
            MockDockerManager.assert_called_once_with({})
            MockWorkspaceStore.assert_called_once_with(str(workspace_path), problem_id="test_contest")
            MockSolveService.assert_called_once_with(mock_llm_instance, mock_docker_instance, mock_workspace_config_instance, mock_ws_store_instance)

            mock_solve_service_instance.run_solve.assert_called_once()
            call_args = mock_solve_service_instance.run_solve.call_args
            assert call_args[1]["problem_text"] == "# Test Problem"
            assert call_args[1]["interactive"] is False
            assert f"Running full solve process in workspace: {workspace_path}" in result.output

    @patch("ahc_agent.cli.DockerManager")
    @patch("ahc_agent.cli.LLMClient")
    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.WorkspaceStore")
    @patch("ahc_agent.cli.SolveService")
    def test_solve_group_default_interactive(self, MockSolveService, MockWorkspaceStore, MockCliConfig, MockLLMClient, MockDockerManager, runner):
        """Tests the default 'solve' command with --interactive flag."""
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.side_effect = lambda key, default=None: {
            "contest_id": "test_interactive_contest",
             "workspace.base_dir": "/mocked/interactive/path",
            "llm": {}, "docker": {},
        }.get(key, default)
        mock_workspace_config_instance.config_file_path = "/mocked/interactive_ws/config.yaml"
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_interactive_solve = AsyncMock(return_value=None)

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            problem_file = workspace_path / "problem.md"
            problem_file.write_text("# Interactive Test Problem")
            config_file = workspace_path / "config.yaml"
            config_file.write_text(yaml.dump({"contest_id": "test_interactive_contest"}))

            result = runner.invoke(cli, ["solve", str(workspace_path), "--interactive"])

            assert result.exit_code == 0, result.output
            # Common setup assertions (Config, LLM, Docker, WorkspaceStore, SolveService instantiation)
            # are similar to non-interactive, so focus on run_interactive_solve call.
            mock_solve_service_instance.run_interactive_solve.assert_called_once()
            call_args = mock_solve_service_instance.run_interactive_solve.call_args
            assert call_args[1]["problem_text_initial"] == "# Interactive Test Problem"
            assert f"Running full solve process in workspace: {workspace_path}" in result.output # This message is still printed by solve group before interactive call

    @patch("ahc_agent.cli.Config") # Mock config loading in parent group
    @patch("ahc_agent.cli.SolveService") # Mock service instance in parent group
    def test_solve_analyze_subcommand(self, MockSolveService, MockCliConfig, runner):
        """Tests the 'solve analyze' subcommand."""
        # Setup mocks for objects created in the parent 'solve' group
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.side_effect = lambda key, default=None: {
            "contest_id": "analyze_test", "workspace.base_dir": "/analyze_ws",
            "llm": {}, "docker": {} }.get(key, default)
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_analyze_step = AsyncMock(return_value={"title": "Analyzed"})

        # Mock WorkspaceStore instance that would be created and put into ctx.obj
        # This is tricky because WorkspaceStore is instantiated inside the solve group function.
        # For subcommands, ctx.obj is populated by the parent. We need to ensure that when
        # MockSolveService is created, it uses a WorkspaceStore that we can also reference.
        # The CLI creates SolveService with a WorkspaceStore instance.
        # We are mocking SolveService itself, so its internal store doesn't matter as much,
        # but the CLI subcommand uses ws_store from ctx.obj for file paths.
        # For this test, we can mock the WorkspaceStore class at ahc_agent.cli level
        # and make its instance have the PROBLEM_ANALYSIS_FILE attribute.
        with patch("ahc_agent.cli.WorkspaceStore") as MockCliWorkspaceStore:
            mock_ws_store_instance_for_cli = MockCliWorkspaceStore.return_value
            mock_ws_store_instance_for_cli.PROBLEM_ANALYSIS_FILE = "problem_analysis.json"


            with runner.isolated_filesystem() as temp_dir:
                workspace_path = Path(temp_dir)
                problem_file = workspace_path / "problem.md"
                problem_file.write_text("# Analyze Problem")
                config_file = workspace_path / "config.yaml"
                config_file.write_text(yaml.dump({"contest_id": "analyze_test"}))

                result = runner.invoke(cli, ["solve", str(workspace_path), "analyze"])

                assert result.exit_code == 0, result.output
                # Assert that the SolveService method was called
                mock_solve_service_instance.run_analyze_step.assert_called_once()
                call_args = mock_solve_service_instance.run_analyze_step.call_args
                assert call_args[1]["problem_text"] == "# Analyze Problem"
                assert f"Running analysis for problem in workspace: {workspace_path}" in result.output
                assert "Analysis complete" in result.output

    def test_solve_subcommand_missing_workspace_files(self, runner):
        """Test that solve subcommands fail if workspace files are missing."""
        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            # Workspace exists but is empty
            workspace_path.mkdir()

            result_analyze = runner.invoke(cli, ["solve", str(workspace_path), "analyze"])
            assert result_analyze.exit_code == 1, "Analyze should fail if problem.md missing"
            assert "problem.md' not found" in result_analyze.output

            # Create problem.md but not config.yaml
            (workspace_path / "problem.md").write_text("dummy problem")
            result_strategy = runner.invoke(cli, ["solve", str(workspace_path), "strategy"])
            assert result_strategy.exit_code == 1, "Strategy should fail if config.yaml missing"
            assert "config.yaml' not found" in result_strategy.output

            # Test missing workspace directory itself
            non_existent_ws = Path(temp_dir) / "no_such_ws"
            result_no_ws = runner.invoke(cli, ["solve", str(non_existent_ws), "analyze"])
            assert result_no_ws.exit_code == 1
            assert "Workspace directory" in result_no_ws.output and "not found" in result_no_ws.output


    # Placeholder for other subcommand tests (strategy, testcases, initial, evolve)
    # These would follow a similar pattern to test_solve_analyze_subcommand:
    # - Mock the specific SolveService method (e.g., run_strategy_step)
    # - Invoke the CLI subcommand (e.g., runner.invoke(cli, ["solve", <ws>, "strategy"]))
    # - Assert the mocked service method was called with correct args (parsed from CLI options)
    # - Test prerequisite file checks specific to the subcommand if any (e.g., strategy needs analysis file)

    # Example for strategy (very basic, needs more detail for options)
    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.SolveService")
    @patch("ahc_agent.cli.WorkspaceStore")
    def test_solve_strategy_subcommand_success(self, MockCliWorkspaceStore, MockSolveService, MockCliConfig, runner):
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.return_value = {"contest_id": "strat_test"}
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_strategy_step = AsyncMock(return_value={"approach": "Mocked Strategy"})

        mock_ws_store_cli_instance = MockCliWorkspaceStore.return_value
        mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE = "problem_analysis.json"
        mock_ws_store_cli_instance.SOLUTION_STRATEGY_FILE = "solution_strategy.json"

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            (workspace_path / "problem.md").write_text("problem") # For parent group
            (workspace_path / "config.yaml").write_text("contest_id: strat_test") # For parent group
            # Simulate analysis file exists for strategy step's specific check
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).write_text("{}")

            result = runner.invoke(cli, ["solve", str(workspace_path), "strategy"])
            assert result.exit_code == 0, result.output
            mock_solve_service_instance.run_strategy_step.assert_called_once()
            assert "Strategy development complete" in result.output

    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.SolveService")
    @patch("ahc_agent.cli.WorkspaceStore")
    def test_solve_strategy_subcommand_no_analysis_file(self, MockCliWorkspaceStore, MockSolveService, MockCliConfig, runner):
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.return_value = {"contest_id": "strat_test_no_analysis"}
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_strategy_step = AsyncMock() # Should not be called

        mock_ws_store_cli_instance = MockCliWorkspaceStore.return_value
        mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE = "problem_analysis.json" # Just for the name

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            (workspace_path / "problem.md").write_text("problem")
            (workspace_path / "config.yaml").write_text("contest_id: strat_test_no_analysis")
            # IMPORTANT: problem_analysis.json is NOT created here

            result = runner.invoke(cli, ["solve", str(workspace_path), "strategy"])

            assert result.exit_code == 1, result.output
            mock_solve_service_instance.run_strategy_step.assert_not_called()
            assert "Problem analysis file ('problem_analysis.json') not found" in result.output
            assert "Please run the 'analyze' step first" in result.output

    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.SolveService")
    @patch("ahc_agent.cli.WorkspaceStore")
    def test_solve_testcases_subcommand(self, MockCliWorkspaceStore, MockSolveService, MockCliConfig, runner):
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.return_value = {"contest_id": "testcases_test"}
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        # run_testcases_step returns a dict: {"test_cases": [], "score_calculator": MagicMock()}
        mock_solve_service_instance.run_testcases_step = AsyncMock(
            return_value={"test_cases": [{"name": "tc1"}], "score_calculator": MagicMock()}
        )

        mock_ws_store_cli_instance = MockCliWorkspaceStore.return_value
        mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE = "problem_analysis.json"

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            (workspace_path / "problem.md").write_text("problem")
            (workspace_path / "config.yaml").write_text("contest_id: testcases_test")
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).write_text("{}") # Prereq for testcases step

            # Test case 1: --load-tools
            result_load = runner.invoke(cli, ["solve", str(workspace_path), "testcases", "--load-tools"])
            assert result_load.exit_code == 0, result_load.output
            mock_solve_service_instance.run_testcases_step.assert_called_with(load_from_tools=True, num_to_generate=3) # Default num_cases
            assert "test cases are now prepared" in result_load.output

            # Test case 2: --force-generate --num-cases 5
            mock_solve_service_instance.run_testcases_step.reset_mock() # Reset for next call
            result_gen = runner.invoke(cli, ["solve", str(workspace_path), "testcases", "--force-generate", "--num-cases", "5"])
            assert result_gen.exit_code == 0, result_gen.output
            mock_solve_service_instance.run_testcases_step.assert_called_with(load_from_tools=False, num_to_generate=5)
            assert "test cases are now prepared" in result_gen.output

            # Test case 3: Default (should generate with default num_cases)
            mock_solve_service_instance.run_testcases_step.reset_mock()
            result_default = runner.invoke(cli, ["solve", str(workspace_path), "testcases"])
            assert result_default.exit_code == 0, result_default.output
            # CLI logic: if not force_generate and not load_tools, service_should_try_load is False
            mock_solve_service_instance.run_testcases_step.assert_called_with(load_from_tools=False, num_to_generate=3)
            assert "test cases are now prepared" in result_default.output

            # Test case 4: Missing analysis file
            mock_solve_service_instance.run_testcases_step.reset_mock()
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).unlink() # Remove analysis file
            result_no_analysis = runner.invoke(cli, ["solve", str(workspace_path), "testcases"])
            assert result_no_analysis.exit_code == 1, result_no_analysis.output
            assert "Problem analysis file ('problem_analysis.json') not found" in result_no_analysis.output
            mock_solve_service_instance.run_testcases_step.assert_not_called()

    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.SolveService")
    @patch("ahc_agent.cli.WorkspaceStore")
    def test_solve_initial_subcommand(self, MockCliWorkspaceStore, MockSolveService, MockCliConfig, runner):
        mock_workspace_config_instance = MagicMock(spec=Config)
        mock_workspace_config_instance.get.return_value = {"contest_id": "initial_test"}
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value
        mock_solve_service_instance.run_initial_solution_step = AsyncMock(return_value="initial_code_here")

        mock_ws_store_cli_instance = MockCliWorkspaceStore.return_value
        mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE = "problem_analysis.json"

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            (workspace_path / "problem.md").write_text("problem")
            (workspace_path / "config.yaml").write_text("contest_id: initial_test")

            # Test success case
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).write_text("{}") # Prereq
            result_success = runner.invoke(cli, ["solve", str(workspace_path), "initial"])
            assert result_success.exit_code == 0, result_success.output
            mock_solve_service_instance.run_initial_solution_step.assert_called_once()
            assert "Initial solution generated and saved" in result_success.output

            # Test missing analysis file
            mock_solve_service_instance.run_initial_solution_step.reset_mock()
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).unlink()
            result_no_analysis = runner.invoke(cli, ["solve", str(workspace_path), "initial"])
            assert result_no_analysis.exit_code == 1, result_no_analysis.output
            assert "Problem analysis file ('problem_analysis.json') not found" in result_no_analysis.output
            mock_solve_service_instance.run_initial_solution_step.assert_not_called()

    @patch("ahc_agent.cli.Config")
    @patch("ahc_agent.cli.SolveService")
    @patch("ahc_agent.cli.WorkspaceStore")
    def test_solve_evolve_subcommand(self, MockCliWorkspaceStore, MockSolveService, MockCliConfig, runner):
        mock_workspace_config_instance = MagicMock(spec=Config)
        # Provide default evolution params for the CLI to pick up if options not given
        mock_workspace_config_instance.get.side_effect = lambda key, default=None: {
            "contest_id": "evolve_test",
            "evolution": {"max_generations": 5, "population_size": 10, "time_limit_seconds": 300}, # Defaults for CLI echo
            "llm": {}, "docker": {}
        }.get(key, default if default is not None else {}) # Ensure nested dicts for 'evolution'
        MockCliConfig.return_value = mock_workspace_config_instance

        mock_solve_service_instance = MockSolveService.return_value

        # Mock for the internal call to run_testcases_step
        mock_test_cases_data = [{"name": "tc_evolve"}]
        mock_score_calc = MagicMock()
        mock_solve_service_instance.run_testcases_step = AsyncMock(
            return_value={"test_cases": mock_test_cases_data, "score_calculator": mock_score_calc}
        )

        # Mock for the main run_evolve_step method
        mock_evolve_results = {"best_solution": "evolved_code", "best_score": 12345, "generations_completed": 5}
        mock_solve_service_instance.run_evolve_step = AsyncMock(return_value=mock_evolve_results)

        mock_ws_store_cli_instance = MockCliWorkspaceStore.return_value
        mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE = "problem_analysis.json"
        mock_ws_store_cli_instance.SOLUTION_STRATEGY_FILE = "solution_strategy.json"
        mock_ws_store_cli_instance.solutions_dir = Path("mocked_solutions_dir") # For output message

        with runner.isolated_filesystem() as temp_dir:
            workspace_path = Path(temp_dir)
            (workspace_path / "problem.md").write_text("problem")
            (workspace_path / "config.yaml").write_text("contest_id: evolve_test")
            (workspace_path / mock_ws_store_cli_instance.PROBLEM_ANALYSIS_FILE).write_text("{}") # Prereq
            (workspace_path / mock_ws_store_cli_instance.SOLUTION_STRATEGY_FILE).write_text("{}") # Prereq

            initial_code_content = "def main(): pass"
            initial_code_file = workspace_path / "my_initial_code.py"
            initial_code_file.write_text(initial_code_content)

            # Test case 1: All options provided
            result_all_opts = runner.invoke(cli, [
                "solve", str(workspace_path), "evolve",
                "--generations", "10",
                "--population", "20",
                "--time-limit", "600",
                "--initial-code-path", str(initial_code_file)
            ])
            assert result_all_opts.exit_code == 0, result_all_opts.output
            mock_solve_service_instance.run_testcases_step.assert_called_once_with(load_from_tools=True, num_to_generate=3) # CLI default for internal call
            mock_solve_service_instance.run_evolve_step.assert_called_once_with(
                test_cases=mock_test_cases_data,
                score_calculator=mock_score_calc,
                max_generations=10,
                population_size=20,
                time_limit_seconds=600,
                initial_code_override=initial_code_content
            )
            assert "Evolution complete" in result_all_opts.output
            assert "Best score achieved: 12345" in result_all_opts.output

            # Test case 2: Default evolution parameters (not specified on CLI)
            mock_solve_service_instance.run_testcases_step.reset_mock()
            mock_solve_service_instance.run_evolve_step.reset_mock()
            result_default_params = runner.invoke(cli, ["solve", str(workspace_path), "evolve"])
            assert result_default_params.exit_code == 0, result_default_params.output
            mock_solve_service_instance.run_testcases_step.assert_called_once_with(load_from_tools=True, num_to_generate=3)
            mock_solve_service_instance.run_evolve_step.assert_called_once_with(
                test_cases=mock_test_cases_data,
                score_calculator=mock_score_calc,
                max_generations=5, # From mock_workspace_config_instance
                population_size=10, # From mock_workspace_config_instance
                time_limit_seconds=300, # From mock_workspace_config_instance
                initial_code_override=None
            )

            # Test case 3: Missing strategy file
            mock_solve_service_instance.run_testcases_step.reset_mock()
            mock_solve_service_instance.run_evolve_step.reset_mock()
            (workspace_path / mock_ws_store_cli_instance.SOLUTION_STRATEGY_FILE).unlink()
            result_no_strategy = runner.invoke(cli, ["solve", str(workspace_path), "evolve"])
            assert result_no_strategy.exit_code == 1, result_no_strategy.output
            assert "Solution strategy file ('solution_strategy.json') not found" in result_no_strategy.output
            mock_solve_service_instance.run_evolve_step.assert_not_called()


# Remove the old test_solve_command_with_workspace and test_solve_command_uses_tools_in_files_simplified
# as their core logic is now covered by the new group tests or would be part of specific subcommand tests if relevant.
# The old test_solve_command was effectively renamed and refactored into test_solve_group_default_non_interactive.
